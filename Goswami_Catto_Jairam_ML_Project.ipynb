{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/avinashjairam/ML_FINAL_PROJECT/blob/main/Goswami_Catto_Jairam_ML_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DBFJ-ToQJA4G"
   },
   "source": [
    "Much of this code adapted from github user ZFTurbo:\n",
    "\n",
    "https://github.com/ZFTurbo/Keras-Mask-RCNN-for-Open-Images-2019-Instance-Segmentation/blob/master/data_segmentation/challenge-2019-classes-description-segmentable.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "4gbTCV8xKEDS"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#os.chdir('')\n",
    "import sys\n",
    "import csv\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "# Root directory of the project\n",
    "#ROOT_DIR = os.path.abspath(\".\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "#sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mask_rcnn.mrcnn import utils\n",
    "import mask_rcnn.mrcnn.model as modellib\n",
    "from mask_rcnn.mrcnn import visualize\n",
    "# Import COCO config\n",
    "#sys.path.append(os.path.join(ROOT_DIR, \"samples/coco/\"))  # To find local version\n",
    "from mask_rcnn.samples.coco import coco\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Directory to save logs and trained model\n",
    "#MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "MODEL_DIR = 'mask_rcnn/logs/'\n",
    "# Local path to trained weights file\n",
    "#COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "COCO_MODEL_PATH = 'mask_rcnn/mask_rcnn_coco.h5'\n",
    "# Download COCO trained weights from Releases if needed\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)\n",
    "\n",
    "# Directory of images to run detection on\n",
    "IMAGE_DIR = \"images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                93\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           coco\n",
      "NUM_CLASSES                    81\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                1000\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class InferenceConfig(coco.CocoConfig):\n",
    "    # Set batch size to 1 since we'll be running inference on\n",
    "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "config = InferenceConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/adamcatto/SRC/ML_FINAL_PROJECT/mask_rcnn/mrcnn/model.py:772: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    }
   ],
   "source": [
    "model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=config)\n",
    "\n",
    "# Load weights trained on MS-COCO\n",
    "model.load_weights(COCO_MODEL_PATH, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'elephant', 'airplane', 'orange', 'laptop', 'person', 'bus', 'train', 'tie', 'cat', 'bowl', 'bottle', 'cake', 'truck', 'motorcycle', 'vase', 'dog', 'car', 'bird', 'traffic light', 'horse', 'couch', 'book', 'handbag'} 23\n"
     ]
    }
   ],
   "source": [
    "# COCO Class names\n",
    "# Index of the class in the list is its ID. For example, to get ID of\n",
    "# the teddy bear class, use: class_names.index('teddy bear')\n",
    "coco_class_names = ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
    "               'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "               'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',\n",
    "               'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',\n",
    "               'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n",
    "               'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "               'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
    "               'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n",
    "               'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "               'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "               'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
    "               'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
    "               'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n",
    "               'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
    "               'teddy bear', 'hair drier', 'toothbrush']\n",
    "\n",
    "oid_class_names = [\n",
    "    'Clothing',\n",
    " 'Girl',\n",
    " 'Car',\n",
    " 'Wheel',\n",
    " 'Person',\n",
    " 'Human body',\n",
    " 'Woman',\n",
    " 'Man',\n",
    " 'Suit',\n",
    " 'Flower',\n",
    " 'Boy',\n",
    " 'Skyscraper',\n",
    " 'Jeans',\n",
    " 'Dress',\n",
    " 'Toy',\n",
    " 'Bicycle wheel',\n",
    " 'Sculpture',\n",
    " 'Bottle',\n",
    " 'Guitar',\n",
    " 'Bird',\n",
    " 'Dog',\n",
    " 'Flag',\n",
    " 'Drink',\n",
    " 'Airplane',\n",
    " 'Flowerpot',\n",
    " 'Shorts',\n",
    " 'Fish',\n",
    " 'Book',\n",
    " 'Motorcycle',\n",
    " 'Cat',\n",
    " 'Truck',\n",
    " 'Hat',\n",
    " 'Human mouth',\n",
    " 'Duck',\n",
    " 'Train',\n",
    " 'Picture frame',\n",
    " 'Horse',\n",
    " 'Tie',\n",
    " 'Bus',\n",
    " 'Laptop',\n",
    " 'Cattle',\n",
    " 'Swimwear',\n",
    " 'Trousers',\n",
    " 'Shirt',\n",
    " 'Balloon',\n",
    " 'Van',\n",
    " 'Goose',\n",
    " 'Beer',\n",
    " 'Rose',\n",
    " 'Sun hat',\n",
    " 'Wine',\n",
    " 'Strawberry',\n",
    " 'Cake',\n",
    " 'Camera',\n",
    " 'Mobile phone',\n",
    " 'Human ear',\n",
    " 'Coffee cup',\n",
    " 'Common sunflower',\n",
    " 'Tomato',\n",
    " 'Box',\n",
    " 'Cocktail',\n",
    " 'Traffic sign',\n",
    " 'Couch',\n",
    " 'Computer keyboard',\n",
    " 'Orange',\n",
    " 'Pumpkin',\n",
    " 'Canoe',\n",
    " 'Muffin',\n",
    " 'Bowl',\n",
    " 'Pillow',\n",
    " 'Christmas tree',\n",
    " 'Taxi',\n",
    " 'Fedora',\n",
    " 'Ball',\n",
    " 'Bread',\n",
    " 'Vehicle registration plate',\n",
    " 'Swan',\n",
    " 'Platter',\n",
    " 'Candle',\n",
    " 'Football',\n",
    " 'Roller skates',\n",
    " 'Pastry',\n",
    " 'Boot',\n",
    " 'Mushroom',\n",
    " 'Monkey',\n",
    " 'Bronze sculpture',\n",
    " 'Cowboy hat', 'High heels',\n",
    " 'Cookie',\n",
    " 'Juice',\n",
    " 'Saucer',\n",
    " 'Traffic light',\n",
    " 'Elephant',\n",
    " 'Handbag',\n",
    " 'Penguin',\n",
    " 'Chicken',\n",
    " 'Carnivore',\n",
    " 'Coin',\n",
    " 'Vase',\n",
    " 'Scarf']\n",
    "\n",
    "oid_class_names = [x.lower() for x in oid_class_names]\n",
    "\n",
    "x = set.intersection(set(coco_class_names), set(oid_class_names))\n",
    "print(x, len(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['puppies.jpg', 'light-switch.png', 'fruit.jpg']\n",
      "Processing 1 images\n",
      "image                    shape: (1024, 1024, 3)       min:    0.00000  max:  248.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  143.10000  float64\n",
      "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  int64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n",
      "Processing 1 images\n",
      "image                    shape: (1024, 1024, 3)       min:    0.00000  max:  255.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
      "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  int64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n",
      "Processing 1 images\n",
      "image                    shape: (512, 512, 3)         min:    0.00000  max:  255.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
      "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
     ]
    }
   ],
   "source": [
    "file_names = list(os.listdir(IMAGE_DIR))\n",
    "results_list = []\n",
    "print(file_names)\n",
    "for f in file_names:\n",
    "    image = skimage.io.imread('images/' + f)\n",
    "    results = model.detect([image], verbose=1)\n",
    "    r = results[0]\n",
    "    #print(type(results))\n",
    "    #visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
    "                            #class_names, r['scores'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training / Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the Mask R-CNN weights pretrained on the Coco dataset. In this project, we will be fine-tuning this model on a subset of the Open Images V6 dataset for the purpose of doing instance segmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "steps:\n",
    "\n",
    "-- cut off top\n",
    "-- freeze model weights\n",
    "-- re-build top\n",
    "-- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "def preprocess(image_set):\n",
    "    # should return list of images all of the same size\n",
    "    pass\n",
    "\n",
    "\n",
    "def fine_tune(model, train_csv_file, num_classes):\n",
    "    # train_csv_file is two columns: raw image | mask\n",
    "    img_list = []\n",
    "    mask_list = []\n",
    "    with open(train_csv_file, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            line = line.split(',')\n",
    "            img_file, mask_file = line[0], line[1]\n",
    "            img = np.array(Image.open(img_file))\n",
    "            mask = None\n",
    "    img_size = x_train[0].shape[0]\n",
    "    inputs = tf.keras.layers.Input(shape=(img_size, img_size, 3))\n",
    "    top_dropout_rate = 0.2\n",
    "    model.fit(x_train, y_train, epochs=16, callbacks=[\n",
    "        tf.keras.callbacks.ModelCheckpoint('fine_tuned_mask_rcnn_oid.h5', verbose=1, save_best_model=True)\n",
    "    ])\n",
    "    return model\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fine_tune() missing 3 required positional arguments: 'x_train', 'y_train', and 'num_classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-de7011e7a079>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfine_tuned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfine_tune\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: fine_tune() missing 3 required positional arguments: 'x_train', 'y_train', and 'num_classes'"
     ]
    }
   ],
   "source": [
    "fine_tuned = fine_tune(model, )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing / Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, x_test, y_test):\n",
    "    pass\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPLfioq4GBvMoXCeyM2s/Dp",
   "include_colab_link": true,
   "name": "Goswami-Catto-Jairam- ML Project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
